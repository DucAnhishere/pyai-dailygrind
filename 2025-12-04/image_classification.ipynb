{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59533948",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "\n",
    "A comprehensive guide to image classification using PyTorch, covering:\n",
    "- Types of classification (single-label, multi-label, fine-grained, zero-shot)\n",
    "- Training loop mechanics\n",
    "- Loss functions and optimizers\n",
    "- Full inference pipeline\n",
    "- Evaluation metrics\n",
    "\n",
    "**Dataset:** Car Corner Classification (12 classes - vehicle viewing angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167ef8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b39150",
   "metadata": {},
   "source": [
    "## 2. Types of Image Classification\n",
    "\n",
    "### Overview\n",
    "\n",
    "| Type | Description | Output | Example |\n",
    "|------|-------------|--------|---------|\n",
    "| **Single-label** | One class per image | Softmax ‚Üí argmax | Cat vs Dog |\n",
    "| **Multi-label** | Multiple classes per image | Sigmoid ‚Üí threshold | Tags: sunny, beach, people |\n",
    "| **Fine-grained** | Distinguish subtle differences within a category | Specialized architectures | Bird species, car models |\n",
    "| **Zero-shot** | Classify without training on specific classes | CLIP-style embeddings | Classify using text descriptions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0dc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-label output (softmax):\n",
      "  Logits shape: torch.Size([1, 12])\n",
      "  After softmax: torch.Size([1, 12]) (sums to 1)\n",
      "  Prediction: class 6\n",
      "\n",
      "Multi-label output (sigmoid):\n",
      "  After sigmoid: torch.Size([1, 12]) (each independent 0-1)\n",
      "  Predictions (threshold=0.5): [True, True, True, True, False, False, True, False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# Example: Single-label vs Multi-label output layers\n",
    "\n",
    "class SingleLabelClassifier(nn.Module):\n",
    "    \"\"\"Single-label: One class per image (mutually exclusive)\"\"\"\n",
    "    def __init__(self, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.backbone = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "        self.backbone.classifier[-1] = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)  # Raw logits ‚Üí use CrossEntropyLoss\n",
    "\n",
    "\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    \"\"\"Multi-label: Multiple classes per image (not mutually exclusive)\"\"\"\n",
    "    def __init__(self, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.backbone = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "        self.backbone.classifier[-1] = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.backbone(x)\n",
    "        return torch.sigmoid(logits)  # Independent probabilities ‚Üí use BCELoss\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "print(\"Single-label output (softmax):\")\n",
    "dummy_logits = torch.randn(1, 12)\n",
    "print(f\"  Logits shape: {dummy_logits.shape}\")\n",
    "print(f\"  After softmax: {torch.softmax(dummy_logits, dim=1).shape} (sums to 1)\")\n",
    "print(f\"  Prediction: class {torch.argmax(dummy_logits, dim=1).item()}\")\n",
    "\n",
    "print(\"\\nMulti-label output (sigmoid):\")\n",
    "print(f\"  After sigmoid: {torch.sigmoid(dummy_logits).shape} (each independent 0-1)\")\n",
    "print(f\"  Predictions (threshold=0.5): {(torch.sigmoid(dummy_logits) > 0.5).squeeze().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9f6b5",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoaders\n",
    "\n",
    "Using the **Car Corner Classification** dataset with 12 viewing angle classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c30473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 12\n",
      "Classes: ['45_phai_sau', '45_phai_truoc', '45_trai_sau', '45_trai_truoc', 'phai_sau_toan_canh', 'phai_toan_canh', 'phai_truoc_toan_canh', 'sau_toan_canh', 'trai_sau_toan_canh', 'trai_toan_canh', 'trai_truoc_toan_canh', 'truoc_toan_canh']\n",
      "\n",
      "Dataset sizes:\n",
      "  Train: 600\n",
      "  Val: 600\n",
      "  Test: 468\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "DATA_ROOT = Path(\"../data/car-corner\")\n",
    "TRAIN_DIR = DATA_ROOT / \"train\"\n",
    "VAL_DIR = DATA_ROOT / \"val\"\n",
    "TEST_DIR = DATA_ROOT / \"test\"\n",
    "\n",
    "# Image transforms\n",
    "IMG_SIZE = 384\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
    "\n",
    "# Class names and mapping\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Dataset sizes\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab894cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "def analyze_dataset_distribution(dataset, class_names, title=\"Dataset Distribution\"):\n",
    "    \"\"\"Analyze and visualize class distribution in dataset.\"\"\"\n",
    "    labels = [label for _, label in dataset.samples]\n",
    "    class_counts = Counter(labels)\n",
    "    \n",
    "    print(f\"\\n{title} - Total images: {len(dataset)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        count = class_counts.get(i, 0)\n",
    "        percentage = (count / len(dataset)) * 100\n",
    "        print(f\"{class_name}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualize distribution\n",
    "    counts = [class_counts.get(i, 0) for i in range(len(class_names))]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(class_names)), counts, color='skyblue')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title(f'{title} - Class Distribution')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_y() + count + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Analyze distributions\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_counts = analyze_dataset_distribution(train_dataset, class_names, \"Training Set\")\n",
    "val_counts = analyze_dataset_distribution(val_dataset, class_names, \"Validation Set\")\n",
    "test_counts = analyze_dataset_distribution(test_dataset, class_names, \"Test Set\")\n",
    "\n",
    "# Summary statistics\n",
    "total_train = len(train_dataset)\n",
    "total_val = len(val_dataset)\n",
    "total_test = len(test_dataset)\n",
    "\n",
    "print(\"\\nSUMMARY STATISTICS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total Training Images:   {total_train}\")\n",
    "print(f\"Total Validation Images: {total_val}\")\n",
    "print(f\"Total Test Images:       {total_test}\")\n",
    "print(f\"Grand Total:             {total_train + total_val + total_test}\")\n",
    "print(f\"Train/Val/Test Split:    {total_train}:{total_val}:{total_test}\")\n",
    "\n",
    "# Check for class imbalance\n",
    "max_count = max(train_counts.values())\n",
    "min_count = min(train_counts.values())\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "print(\"\\nClass Imbalance Analysis:\")\n",
    "print(f\"Max class count: {max_count}\")\n",
    "print(f\"Min class count: {min_count}\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 2.0:\n",
    "    print(\"‚ö†Ô∏è  Dataset has significant class imbalance - consider using weighted loss or data augmentation\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset is relatively balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Visualize sample batch\n",
    "def show_batch(dataloader, class_names, n=8):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images[:n] * std + mean\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < n:\n",
    "            img = images_denorm[idx].permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(class_names[labels[idx]], fontsize=10)\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_batch(train_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62335940",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "Using **MobileNetV3-Small** with transfer learning (pretrained on ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, pretrained=True, freeze_backbone=False):\n",
    "    \"\"\"\n",
    "    Create MobileNetV3-Small model with custom classification head.\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        pretrained: Use ImageNet pretrained weights\n",
    "        freeze_backbone: Freeze feature extractor (for feature extraction mode)\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        model = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "    else:\n",
    "        model = models.mobilenet_v3_small(weights=None)\n",
    "    \n",
    "    # Freeze backbone if needed (feature extraction mode)\n",
    "    if freeze_backbone:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Modify classification head\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_model(num_classes=num_classes, pretrained=True, freeze_backbone=False)\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "print(f\"Model: MobileNetV3-Small\")\n",
    "print(f\"Input size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Output classes: {num_classes}\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f50fa",
   "metadata": {},
   "source": [
    "## 5. Loss Functions\n",
    "\n",
    "### Key Loss Functions for Classification\n",
    "\n",
    "| Loss Function | Use Case | Formula |\n",
    "|--------------|----------|---------|\n",
    "| **CrossEntropyLoss** | Single-label classification | $-\\sum_i y_i \\log(\\hat{y}_i)$ |\n",
    "| **BCELoss** | Multi-label (after sigmoid) | $-\\frac{1}{N}\\sum[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})]$ |\n",
    "| **BCEWithLogitsLoss** | Multi-label (raw logits) | BCE + Sigmoid combined |\n",
    "| **Focal Loss** | Imbalanced datasets | $-\\alpha(1-\\hat{y})^\\gamma \\log(\\hat{y})$ |\n",
    "| **Weighted CrossEntropy** | Class imbalance | CrossEntropy with class weights |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Loss Function Implementations\n",
    "# =====================\n",
    "\n",
    "# 1. Standard CrossEntropyLoss (Single-label)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# 2. BCEWithLogitsLoss (Multi-label)\n",
    "criterion_bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 3. Weighted CrossEntropyLoss (for imbalanced datasets)\n",
    "def compute_class_weights(dataset):\n",
    "    \"\"\"Compute inverse frequency weights for each class.\"\"\"\n",
    "    labels = [label for _, label in dataset.samples]\n",
    "    class_counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "    weights = torch.tensor([total / class_counts[i] for i in range(len(class_counts))])\n",
    "    return weights / weights.sum() * len(weights)  # Normalize\n",
    "\n",
    "class_weights = compute_class_weights(train_dataset)\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "criterion_weighted = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "\n",
    "# 4. Focal Loss (reduces impact of easy samples, good for imbalanced data)\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for addressing class imbalance.\n",
    "    \n",
    "    FL(p_t) = -Œ±_t * (1 - p_t)^Œ≥ * log(p_t)\n",
    "    \n",
    "    Args:\n",
    "        alpha: Weighting factor (default: 1)\n",
    "        gamma: Focusing parameter (default: 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # probability of correct class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n",
    "\n",
    "criterion_focal = FocalLoss(alpha=1, gamma=2)\n",
    "\n",
    "# Demonstration\n",
    "print(\"\\n--- Loss Function Demo ---\")\n",
    "dummy_logits = torch.randn(4, num_classes)\n",
    "dummy_targets = torch.tensor([0, 1, 2, 3])\n",
    "\n",
    "print(f\"CrossEntropy Loss: {criterion_ce(dummy_logits, dummy_targets):.4f}\")\n",
    "print(f\"Focal Loss (Œ≥=2): {criterion_focal(dummy_logits, dummy_targets):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b9615",
   "metadata": {},
   "source": [
    "## 6. Optimizers\n",
    "\n",
    "### Optimizer Comparison\n",
    "\n",
    "| Optimizer | Characteristics | Best For |\n",
    "|-----------|----------------|----------|\n",
    "| **SGD** | Simple, strong generalization, needs LR scheduling | CNNs, final fine-tuning |\n",
    "| **Adam** | Adaptive LR, fast convergence | Quick experiments, RNNs |\n",
    "| **AdamW** | Adam + decoupled weight decay | Transformers, ViTs |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Optimizer Configurations\n",
    "# =====================\n",
    "\n",
    "# Learning rate\n",
    "LR = 1e-3\n",
    "\n",
    "# 1. SGD with momentum\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# 2. Adam\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999), weight_decay=1e-4)\n",
    "\n",
    "# 3. AdamW (preferred for Transformers)\n",
    "optimizer_adamw = optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "\n",
    "# Learning Rate Schedulers\n",
    "# StepLR: Decay LR by gamma every step_size epochs\n",
    "scheduler_step = optim.lr_scheduler.StepLR(optimizer_adam, step_size=10, gamma=0.1)\n",
    "\n",
    "# CosineAnnealing: Smooth decay following cosine curve\n",
    "scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer_adam, T_max=30, eta_min=1e-6)\n",
    "\n",
    "# ReduceLROnPlateau: Reduce LR when metric plateaus\n",
    "scheduler_plateau = optim.lr_scheduler.ReduceLROnPlateau(optimizer_adam, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# For this notebook, we'll use AdamW with CosineAnnealing\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={LR}, weight_decay=0.01)\")\n",
    "print(f\"Scheduler: CosineAnnealingLR (T_max=30)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4d8a5",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "The core training loop consists of:\n",
    "1. **Forward pass** - Input ‚Üí Model ‚Üí Predictions\n",
    "2. **Compute loss** - Compare predictions to targets\n",
    "3. **Backpropagation** - Compute gradients\n",
    "4. **Update weights** - Optimizer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "    \n",
    "    Training Loop Steps:\n",
    "    1. Forward pass: predictions = model(inputs)\n",
    "    2. Compute loss: loss = criterion(predictions, targets)\n",
    "    3. Backpropagation: loss.backward()\n",
    "    4. Update weights: optimizer.step()\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    for images, labels in pbar:\n",
    "        # Move to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 2. Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 3. Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4. Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100.*correct/total})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10, save_path=\"best_model.pth\"):\n",
    "    \"\"\"\n",
    "    Full training loop with validation and checkpointing.\n",
    "    \"\"\"\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "            }, save_path)\n",
    "            print(f\"‚úì Saved best model (val_acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Use CrossEntropyLoss for single-label classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Criterion: CrossEntropyLoss\")\n",
    "print(f\"  Optimizer: AdamW\")\n",
    "print(f\"  Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898579fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (set num_epochs as needed)\n",
    "NUM_EPOCHS = 5  # Increase for better results\n",
    "\n",
    "history = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    save_path=\"car_corner_best.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf97b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[2].plot(history['lr'])\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title('Learning Rate Schedule')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36606231",
   "metadata": {},
   "source": [
    "## 8. Full Inference Pipeline\n",
    "\n",
    "Complete end-to-end pipeline:\n",
    "1. **Input image** ‚Üí Load from file\n",
    "2. **Preprocessing** ‚Üí Resize, normalize, convert to tensor\n",
    "3. **Feature extraction** ‚Üí Forward through backbone\n",
    "4. **Classification head** ‚Üí Final linear layer\n",
    "5. **Prediction** ‚Üí Softmax ‚Üí argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationPipeline:\n",
    "    \"\"\"\n",
    "    Complete inference pipeline for image classification.\n",
    "    \n",
    "    Pipeline stages:\n",
    "    1. Input image (file path or PIL Image)\n",
    "    2. Preprocessing (resize, normalize)\n",
    "    3. Feature extraction (backbone forward pass)\n",
    "    4. Classification head (final layer)\n",
    "    5. Prediction (softmax + argmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, class_names, device, img_size=384):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.device = device\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Preprocessing transform\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        \"\"\"Stage 2: Preprocess image.\"\"\"\n",
    "        if isinstance(image, str):\n",
    "            image = Image.open(image).convert('RGB')\n",
    "        return self.transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, image, top_k=5):\n",
    "        \"\"\"\n",
    "        Run full inference pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            dict with predicted class, confidence, and top-k predictions\n",
    "        \"\"\"\n",
    "        # 1. Input image\n",
    "        if isinstance(image, str):\n",
    "            original_image = Image.open(image).convert('RGB')\n",
    "        else:\n",
    "            original_image = image\n",
    "        \n",
    "        # 2. Preprocessing\n",
    "        input_tensor = self.preprocess(original_image).to(self.device)\n",
    "        \n",
    "        # 3 & 4. Feature extraction + Classification head (forward pass)\n",
    "        logits = self.model(input_tensor)\n",
    "        \n",
    "        # 5. Prediction (softmax + top-k)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, k=min(top_k, len(self.class_names)))\n",
    "        \n",
    "        # Get results\n",
    "        predicted_class = self.class_names[top_indices[0, 0].item()]\n",
    "        confidence = top_probs[0, 0].item()\n",
    "        \n",
    "        top_k_results = [\n",
    "            (self.class_names[idx.item()], prob.item())\n",
    "            for idx, prob in zip(top_indices[0], top_probs[0])\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence,\n",
    "            'top_k': top_k_results,\n",
    "            'original_image': original_image\n",
    "        }\n",
    "    \n",
    "    def visualize_prediction(self, result):\n",
    "        \"\"\"Visualize prediction with top-k bar chart.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Show image\n",
    "        axes[0].imshow(result['original_image'])\n",
    "        axes[0].set_title(f\"Predicted: {result['predicted_class']}\\nConfidence: {result['confidence']:.2%}\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Top-k bar chart\n",
    "        classes = [x[0] for x in result['top_k']]\n",
    "        probs = [x[1] for x in result['top_k']]\n",
    "        colors = ['green' if i == 0 else 'steelblue' for i in range(len(classes))]\n",
    "        \n",
    "        axes[1].barh(classes[::-1], probs[::-1], color=colors[::-1])\n",
    "        axes[1].set_xlabel('Probability')\n",
    "        axes[1].set_title('Top-5 Predictions')\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        \n",
    "        for i, (cls, prob) in enumerate(zip(classes[::-1], probs[::-1])):\n",
    "            axes[1].text(prob + 0.02, i, f'{prob:.2%}', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Load best model and create pipeline\n",
    "checkpoint = torch.load(\"car_corner_best.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model (val_acc: {checkpoint['val_acc']:.2f}%)\")\n",
    "\n",
    "pipeline = ImageClassificationPipeline(model, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14101f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pipeline on a sample image\n",
    "sample_images = list(TEST_DIR.glob(\"*/*.jpg\"))[:3]\n",
    "\n",
    "for img_path in sample_images:\n",
    "    result = pipeline.predict(str(img_path))\n",
    "    print(f\"\\nImage: {img_path.name}\")\n",
    "    print(f\"Predicted: {result['predicted_class']} ({result['confidence']:.2%})\")\n",
    "    pipeline.visualize_prediction(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06697058",
   "metadata": {},
   "source": [
    "## 9. Evaluation Metrics\n",
    "\n",
    "### Classification Metrics Summary\n",
    "\n",
    "| Metric | Description | Formula |\n",
    "|--------|-------------|---------|\n",
    "| **Accuracy** | Overall correctness | $\\frac{TP + TN}{Total}$ |\n",
    "| **Precision** | Of predicted positives, how many are correct | $\\frac{TP}{TP + FP}$ |\n",
    "| **Recall** | Of actual positives, how many were found | $\\frac{TP}{TP + FN}$ |\n",
    "| **F1 Score** | Harmonic mean of precision and recall | $2 \\cdot \\frac{P \\cdot R}{P + R}$ |\n",
    "\n",
    "### Multi-class Averaging\n",
    "\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| **Macro** | Average metrics across all classes (equal weight) |\n",
    "| **Weighted** | Average weighted by class support |\n",
    "| **Top-5 Accuracy** | Correct if true label in top 5 predictions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff369d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(outputs, targets, k=5):\n",
    "    \"\"\"\n",
    "    Compute top-k accuracy.\n",
    "    \n",
    "    Correct if the true label is among the top k predictions.\n",
    "    \"\"\"\n",
    "    _, top_k_preds = outputs.topk(k, dim=1)\n",
    "    correct = top_k_preds.eq(targets.view(-1, 1).expand_as(top_k_preds))\n",
    "    return correct.any(dim=1).float().mean().item() * 100\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, class_names, device):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with all metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_outputs.append(outputs.cpu())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    \n",
    "    # Per-class and averaged metrics\n",
    "    precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0) * 100\n",
    "    precision_weighted = precision_score(all_labels, all_preds, average='weighted', zero_division=0) * 100\n",
    "    \n",
    "    recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0) * 100\n",
    "    recall_weighted = recall_score(all_labels, all_preds, average='weighted', zero_division=0) * 100\n",
    "    \n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0) * 100\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0) * 100\n",
    "    \n",
    "    # Top-k accuracy\n",
    "    top5_acc = compute_top_k_accuracy(all_outputs, torch.tensor(all_labels), k=5)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'top5_accuracy': top5_acc,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_macro': recall_macro,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_metrics(results):\n",
    "    \"\"\"Print evaluation metrics in a formatted way.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"EVALUATION METRICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nüìä Overall Metrics:\")\n",
    "    print(f\"   Accuracy:      {results['accuracy']:.2f}%\")\n",
    "    print(f\"   Top-5 Accuracy: {results['top5_accuracy']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìà Precision:\")\n",
    "    print(f\"   Macro:    {results['precision_macro']:.2f}%\")\n",
    "    print(f\"   Weighted: {results['precision_weighted']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìâ Recall:\")\n",
    "    print(f\"   Macro:    {results['recall_macro']:.2f}%\")\n",
    "    print(f\"   Weighted: {results['recall_weighted']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüéØ F1 Score:\")\n",
    "    print(f\"   Macro:    {results['f1_macro']:.2f}%\")\n",
    "    print(f\"   Weighted: {results['f1_weighted']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìã Per-Class Report:\")\n",
    "    print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "results = evaluate_model(model, test_loader, class_names, device)\n",
    "print_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34503fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, figsize=(12, 10)):\n",
    "    \"\"\"Plot confusion matrix as heatmap.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Normalize confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm_normalized, \n",
    "        annot=True, \n",
    "        fmt='.2f', \n",
    "        cmap='Blues',\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        square=True\n",
    "    )\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(results['confusion_matrix'], class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a253df3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Topic | Key Points |\n",
    "|-------|------------|\n",
    "| **Classification Types** | Single-label (softmax), Multi-label (sigmoid), Fine-grained, Zero-shot |\n",
    "| **Training Loop** | Forward ‚Üí Loss ‚Üí Backward ‚Üí Update |\n",
    "| **Loss Functions** | CrossEntropy (single), BCE (multi), Focal (imbalanced) |\n",
    "| **Optimizers** | SGD (generalization), Adam (fast), AdamW (Transformers) |\n",
    "| **Pipeline** | Input ‚Üí Preprocess ‚Üí Feature Extract ‚Üí Classify ‚Üí Predict |\n",
    "| **Metrics** | Accuracy, Precision, Recall, F1, Confusion Matrix, Top-k |\n",
    "\n",
    "### Next Steps\n",
    "- Try different backbones (ResNet, EfficientNet, ViT)\n",
    "- Experiment with data augmentation (Albumentations)\n",
    "- Implement learning rate finder\n",
    "- Add mixed precision training (torch.cuda.amp)\n",
    "- Export model for deployment (ONNX, TorchScript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ducanh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
